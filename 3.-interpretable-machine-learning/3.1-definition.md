# 3.1 Definition

 An **interpretable model** helps you to understand and account for the factors that are \(not\) included in the **model** and account for the context of the problem when taking actions based on **model** predictions. Improving generalization and performance. A high **interpretability** typically leads to a **model** that generalizes better.

![Flow for an Interpretable Models](../.gitbook/assets/image%20%287%29.png)

