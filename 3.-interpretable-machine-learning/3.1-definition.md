# 3.1 Definition

An **interpretable model** helps you to understand and account for the factors that are \(not\) included in the **model** and account for the context of the problem when taking actions based on **model** predictions. Improving generalization and performance. High **interpretability** typically leads to a **model** that generalizes better.

![Flow for an Interpretable Models \(Ref. https://christophm.github.io/interpretable-ml-book/agnostic.html\)](../.gitbook/assets/image%20%287%29.png)

