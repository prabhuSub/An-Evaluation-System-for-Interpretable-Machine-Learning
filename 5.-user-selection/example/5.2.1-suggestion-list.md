# 5.2.1 Suggestion Lists

## 5.2.1.1 Model-Specific

The following features are selected by the user:

* **Interaction**
* **Parametric**
* **Algorithmic complexity**

According to the score table, we can get:

|  | Interaction | Parametric | Algorithmic complexity | SUM | AVERAGE | SUGGESTION |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| GLM | 1 | 1 | 1 | 3 | 2 | STRONG |
| Gradient Boosting | 0.7 | 1 | 0.8 | 2.5 | 2 | STRONG |
| XGBoost | 0.7 | 0.9 | 0.7 | 2.3 | 2 | STRONG |
| Distributed Random Forest | 0.7 | 1 | 0.9 | 2.6 | 2 | STRONG |
| Deep Learning | 0 | 0.1 | 0.2 | 0.3 | 2 | LIGHTLY |
| K-means | 0.1 | 0.7 | 0.5 | 1.3 | 2 | MEDIUM |

Therefore, the Model-Specific methods we suggest using are:

* **GLM**
* **Gradient Boosting**
* **XGBoost**
* **Distributed Random Forest**

## 5.2.1.2 Model-Agnostic

The following features are selected by the user:

* **Model internals**
* **Datapoint**
* **Detailed**
* **Certainty** 

According to the score table, we can get:

|  | Model internals | Datapoint | Detailed | Certainty | SUM | AVERAGE | SUGGESTION |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| Variable Importance / Standardized Coefficient | 1 | 0.5 | 1 | 1 | 3.5 | 2.6 | STRONG |
| PDP | 0.1 | 0.9 | 0.5 | 0.8 | 2.3 | 2.6 | MEDIUM |
| ICE | 0.2 | 1 | 1 | 0.9 | 3.1 | 2.6 | STRONG |
| ALE | 0 | 0.9 | 0.6 | 0 | 1.5 | 2.6 | LIGHTLY |

Therefore, the Model-Agnostic methods we suggest using are 

* **Variable Importance**
* **PDP**
* **ICE**

